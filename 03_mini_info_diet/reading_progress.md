# Reading progress

Instructions: update this file with your feedback. Use statuses: not started / in progress / 25% / 50% / 75% / finished. Add short notes where helpful.

Top 3 selected papers:

1. ToolRL: Reward is All Tool Learning Needs
   - Status: finished
   - Notes: This paper redefines tool-use in agentic AI by eliminating the need for complex reward shaping, enabling scalable and generalizable tool learning—crucial for multi-agent and tool-rich environments. Read.
   - Scores: applicability=9, impact=9, innovation=10, inspiration=9, aggregate=9.25

2. MAT-Agent: Adaptive Multi-Agent Training Optimization
   - Status: not started
   - Notes: MAT-Agent introduces adaptive optimization for multi-agent systems, addressing the core challenge of coordinating diverse agents—an essential step for scalable multi-agent learning.
   - Scores: applicability=10, impact=9, innovation=9, inspiration=9, aggregate=9.00

3. MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning
   - Status: not started
   - Notes: This work pioneers integrating Theory of Mind into embodied agents, enabling lifelong learning and richer social interactions, which is foundational for advanced agentic AI systems.
   - Scores: applicability=8, impact=10, innovation=10, inspiration=9, aggregate=9.25

How to update: tell me which paper number and new status/notes; I will update this file accordingly.

Today's top 3 picks:

1. From Euler to AI: Unifying Formulas for Mathematical Constants
   - Status: not started
   - Summary: 

2. MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning
   - Status: not started
   - Summary: 

3. DistillRecDial: A Knowledge-Distilled Dataset for Conversational RecSys
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. CTRL-ALT-DECEIT Sabotage Evaluations for Automated AI R&D
   - Status: not started
   - Summary: 

2. RAG4GFM: Graph Retrieval Augmented Generation
   - Status: not started
   - Summary: 

3. Tight analyses of first-order methods with error feedback
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Addressing Multi-stakeholder Fairness Concerns in Recommender Systems
   - Status: not started
   - Summary: 

2. CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures
   - Status: not started
   - Summary: 

3. HyperMARL: Adaptive Hypernetworks for Multi-Agent RL
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image
   - Status: not started
   - Summary: 

2. Agnostic Active Learning Is Always Better Than Passive Learning
   - Status: not started
   - Summary: 

3. From Euler to AI: Unifying Formulas for Mathematical Constants
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Counterfactual Reasoning for Steerable Pluralistic Value Alignment of Large Language Models
   - Status: not started
   - Summary: 

2. Blindfolded Experts Generalize Better: Insights from Robotic Manipulation
   - Status: not started
   - Summary: 

3. DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. HyperMARL: Adaptive Hypernetworks for Multi-Agent RL
   - Status: not started
   - Summary: 

2. ToolRL: Reward is All Tool Learning Needs
   - Status: not started
   - Summary: 

3. From Euler to AI: Unifying Formulas for Mathematical Constants
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Dynamic Risk Assessments for Offensive Cybersecurity Agents
   - Status: not started
   - Summary: 

2. LLMs as Reliable Evaluators for Serendipity Evaluation in RecSys
   - Status: not started
   - Summary: 

3. DISCOVER: Automated Curricula for Sparse-Reward RL
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Beyond Next Token Prediction: Patch-Level Training for Large Language Models
   - Status: not started
   - Summary: 

2. Uni-RL: Unifying Online and Offline RL via Implicit Value Regularization
   - Status: not started
   - Summary: 

3. Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. http://arxiv.org/abs/2505.23620v1
   - Status: not started
   - Summary: 

2. http://arxiv.org/abs/2505.19955v3
   - Status: not started
   - Summary: 

3. http://arxiv.org/abs/2412.04233v4
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Benefiting from Negative yet Informative Feedback by Contrasting Opposing Sequential Patterns
   - Status: not started
   - Summary: 
   - Digest: We consider the task of learning from both positive and negative feedback in a sequential recommendation scenario, as both types of feedback are often present in user interactions. Meanwhile, conventional sequential learning models usually focus on considering and predicting positive interactions, i
   - ArXiv: http://arxiv.org/abs/2508.14786v1

2. Memory-Enhanced Neural Solvers for Routing Problems
   - Status: not started
   - Summary: 
   - Digest: Routing Problems are central to many real-world applications, yet remain challenging due to their (NP-)hard nature. Amongst existing approaches, heuristics often offer the best trade-off between quality and scalability, making them suitable for industrial use. While Reinforcement Learning (RL) offer
   - ArXiv: http://arxiv.org/abs/2406.16424v3

3. Instance-Optimality for Private KL Distribution Estimation
   - Status: not started
   - Summary: 
   - Digest: We study the fundamental problem of estimating an unknown discrete distribution $p$ over $d$ symbols, given $n$ i.i.d. samples from the distribution. We are interested in minimizing the KL divergence between the true distribution and the algorithm's estimate. We first construct minimax optimal priva
   - ArXiv: http://arxiv.org/abs/2505.23620v1



Today's top 3 picks:

1. A Dual-Key Attention Framework for Sequential Recommendation with Side Information
   - Status: not started
   - Summary: 

2. PREAMBLE: Private and Efficient Aggregation via Block Sparse Vectors
   - Status: not started
   - Summary: 
   - Digest: We revisit the problem of secure aggregation of high-dimensional vectors in a two-server system such as Prio. These systems are typically used to aggregate vectors such as gradients in private federated learning, where the aggregate itself is protected via noise addition to ensure differential priva
   - ArXiv: http://arxiv.org/abs/2503.11897v2

3. Noise Injection Reveals Hidden Capabilities of Sandbagging LLMs
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Info-Theoretic Reward Decomposition for Generalizable RLHF
   - Status: not started
   - Summary: 

2. Stable Gradients for Stable Learning at Scale in Deep Reinforcement Learning
   - Status: not started
   - Summary: 
   - Digest: Scaling deep reinforcement learning networks is challenging and often results in degraded performance, yet the root causes of this failure mode remain poorly understood. Several recent works have proposed mechanisms to address this, but they are often complex and fail to highlight the causes underly
   - ArXiv: http://arxiv.org/abs/2506.15544v1

3. PREAMBLE: Private and Efficient Aggregation via Block Sparse Vectors
   - Status: not started
   - Summary: 
   - Digest: We revisit the problem of secure aggregation of high-dimensional vectors in a two-server system such as Prio. These systems are typically used to aggregate vectors such as gradients in private federated learning, where the aggregate itself is protected via noise addition to ensure differential priva
   - ArXiv: http://arxiv.org/abs/2503.11897v2

