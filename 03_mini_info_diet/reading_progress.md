# Reading progress

Instructions: update this file with your feedback. Use statuses: not started / in progress / 25% / 50% / 75% / finished. Add short notes where helpful.

Top 3 selected papers:

1. ToolRL: Reward is All Tool Learning Needs
   - Status: finished
   - Notes: This paper redefines tool-use in agentic AI by eliminating the need for complex reward shaping, enabling scalable and generalizable tool learning—crucial for multi-agent and tool-rich environments. Read.
   - Scores: applicability=9, impact=9, innovation=10, inspiration=9, aggregate=9.25

2. MAT-Agent: Adaptive Multi-Agent Training Optimization
   - Status: not started
   - Notes: MAT-Agent introduces adaptive optimization for multi-agent systems, addressing the core challenge of coordinating diverse agents—an essential step for scalable multi-agent learning.
   - Scores: applicability=10, impact=9, innovation=9, inspiration=9, aggregate=9.00

3. MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning
   - Status: not started
   - Notes: This work pioneers integrating Theory of Mind into embodied agents, enabling lifelong learning and richer social interactions, which is foundational for advanced agentic AI systems.
   - Scores: applicability=8, impact=10, innovation=10, inspiration=9, aggregate=9.25

How to update: tell me which paper number and new status/notes; I will update this file accordingly.

Today's top 3 picks:

1. From Euler to AI: Unifying Formulas for Mathematical Constants
   - Status: not started
   - Summary: 

2. MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning
   - Status: not started
   - Summary: 

3. DistillRecDial: A Knowledge-Distilled Dataset for Conversational RecSys
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. CTRL-ALT-DECEIT Sabotage Evaluations for Automated AI R&D
   - Status: not started
   - Summary: 

2. RAG4GFM: Graph Retrieval Augmented Generation
   - Status: not started
   - Summary: 

3. Tight analyses of first-order methods with error feedback
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Addressing Multi-stakeholder Fairness Concerns in Recommender Systems
   - Status: not started
   - Summary: 

2. CORE: Measuring Multi-Agent LLM Interaction Quality under Game-Theoretic Pressures
   - Status: not started
   - Summary: 

3. HyperMARL: Adaptive Hypernetworks for Multi-Agent RL
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image
   - Status: not started
   - Summary: 

2. Agnostic Active Learning Is Always Better Than Passive Learning
   - Status: not started
   - Summary: 

3. From Euler to AI: Unifying Formulas for Mathematical Constants
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Counterfactual Reasoning for Steerable Pluralistic Value Alignment of Large Language Models
   - Status: not started
   - Summary: 

2. Blindfolded Experts Generalize Better: Insights from Robotic Manipulation
   - Status: not started
   - Summary: 

3. DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. HyperMARL: Adaptive Hypernetworks for Multi-Agent RL
   - Status: not started
   - Summary: 

2. ToolRL: Reward is All Tool Learning Needs
   - Status: not started
   - Summary: 

3. From Euler to AI: Unifying Formulas for Mathematical Constants
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Dynamic Risk Assessments for Offensive Cybersecurity Agents
   - Status: not started
   - Summary: 

2. LLMs as Reliable Evaluators for Serendipity Evaluation in RecSys
   - Status: not started
   - Summary: 

3. DISCOVER: Automated Curricula for Sparse-Reward RL
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Beyond Next Token Prediction: Patch-Level Training for Large Language Models
   - Status: not started
   - Summary: 

2. Uni-RL: Unifying Online and Offline RL via Implicit Value Regularization
   - Status: not started
   - Summary: 

3. Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. http://arxiv.org/abs/2505.23620v1
   - Status: not started
   - Summary: 

2. http://arxiv.org/abs/2505.19955v3
   - Status: not started
   - Summary: 

3. http://arxiv.org/abs/2412.04233v4
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Benefiting from Negative yet Informative Feedback by Contrasting Opposing Sequential Patterns
   - Status: not started
   - Summary: 
   - Digest: We consider the task of learning from both positive and negative feedback in a sequential recommendation scenario, as both types of feedback are often present in user interactions. Meanwhile, conventional sequential learning models usually focus on considering and predicting positive interactions, i
   - ArXiv: http://arxiv.org/abs/2508.14786v1

2. Memory-Enhanced Neural Solvers for Routing Problems
   - Status: not started
   - Summary: 
   - Digest: Routing Problems are central to many real-world applications, yet remain challenging due to their (NP-)hard nature. Amongst existing approaches, heuristics often offer the best trade-off between quality and scalability, making them suitable for industrial use. While Reinforcement Learning (RL) offer
   - ArXiv: http://arxiv.org/abs/2406.16424v3

3. Instance-Optimality for Private KL Distribution Estimation
   - Status: not started
   - Summary: 
   - Digest: We study the fundamental problem of estimating an unknown discrete distribution $p$ over $d$ symbols, given $n$ i.i.d. samples from the distribution. We are interested in minimizing the KL divergence between the true distribution and the algorithm's estimate. We first construct minimax optimal priva
   - ArXiv: http://arxiv.org/abs/2505.23620v1



Today's top 3 picks:

1. A Dual-Key Attention Framework for Sequential Recommendation with Side Information
   - Status: not started
   - Summary: 

2. PREAMBLE: Private and Efficient Aggregation via Block Sparse Vectors
   - Status: not started
   - Summary: 
   - Digest: We revisit the problem of secure aggregation of high-dimensional vectors in a two-server system such as Prio. These systems are typically used to aggregate vectors such as gradients in private federated learning, where the aggregate itself is protected via noise addition to ensure differential priva
   - ArXiv: http://arxiv.org/abs/2503.11897v2

3. Noise Injection Reveals Hidden Capabilities of Sandbagging LLMs
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Info-Theoretic Reward Decomposition for Generalizable RLHF
   - Status: not started
   - Summary: 

2. Stable Gradients for Stable Learning at Scale in Deep Reinforcement Learning
   - Status: not started
   - Summary: 
   - Digest: Scaling deep reinforcement learning networks is challenging and often results in degraded performance, yet the root causes of this failure mode remain poorly understood. Several recent works have proposed mechanisms to address this, but they are often complex and fail to highlight the causes underly
   - ArXiv: http://arxiv.org/abs/2506.15544v1

3. PREAMBLE: Private and Efficient Aggregation via Block Sparse Vectors
   - Status: not started
   - Summary: 
   - Digest: We revisit the problem of secure aggregation of high-dimensional vectors in a two-server system such as Prio. These systems are typically used to aggregate vectors such as gradients in private federated learning, where the aggregate itself is protected via noise addition to ensure differential priva
   - ArXiv: http://arxiv.org/abs/2503.11897v2



Today's top 3 picks:

1. Bilevel ZOFO: Efficient LLM Fine-Tuning and Meta-Training
   - Status: not started
   - Summary: 
   - Digest: Fine-tuning pre-trained Large Language Models (LLMs) for downstream tasks using First-Order (FO) optimizers presents significant computational challenges. Parameter-Efficient Fine-Tuning (PEFT) methods address these by freezing most model parameters and training only a small subset. However, PEFT of
   - ArXiv: http://arxiv.org/abs/2502.03604v2

2. HyperMARL: Adaptive Hypernetworks for Multi-Agent RL
   - Status: not started
   - Summary: 
   - Digest: Adaptive cooperation in multi-agent reinforcement learning (MARL) requires policies to express homogeneous, specialised, or mixed behaviours, yet achieving this adaptivity remains a critical challenge. While parameter sharing (PS) is standard for efficient learning, it notoriously suppresses the beh
   - ArXiv: http://arxiv.org/abs/2412.04233v4

3. Bayesian Concept Bottleneck Models with LLM Priors
   - Status: not started
   - Summary: 
   - Digest: Concept Bottleneck Models (CBMs) have been proposed as a compromise between white-box and black-box models, aiming to achieve interpretability without sacrificing accuracy. The standard training procedure for CBMs is to predefine a candidate set of human-interpretable concepts, extract their values 
   - ArXiv: http://arxiv.org/abs/2410.15555v2



Today's top 3 picks:

1. GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration
   - Status: not started
   - Summary: 
   - Digest: We propose GAM-Agent, a game-theoretic multi-agent framework for enhancing vision-language reasoning. Unlike prior single-agent or monolithic models, GAM-Agent formulates the reasoning process as a non-zero-sum game between base agents--each specializing in visual perception subtasks--and a critical
   - ArXiv: http://arxiv.org/abs/2505.23399v1

2. Simultaneous Preference and Metric Learning from Paired Comparisons
   - Status: not started
   - Summary: 
   - Digest: A popular model of preference in the context of recommendation systems is the so-called \emph{ideal point} model. In this model, a user is represented as a vector $\mathbf{u}$ together with a collection of items $\mathbf{x_1}, \ldots, \mathbf{x_N}$ in a common low-dimensional space. The vector $\mat
   - ArXiv: http://arxiv.org/abs/2009.02302v2

3. Reinforcing Multi-Turn Reasoning in LLM Agents via Turn-Level Reward Design
   - Status: not started
   - Summary: 
   - Digest: This paper investigates Reinforcement Learning (RL) approaches to enhance the reasoning capabilities of Large Language Model (LLM) agents in long-horizon, multi-turn scenarios. Although RL algorithms such as Group Relative Policy Optimization (GRPO) and Proximal Policy Optimization (PPO) have been w
   - ArXiv: http://arxiv.org/abs/2505.11821v2



Today's top 3 picks:

1. "Recite, Reconstruct, Recollect: Memorization in LMs as a Multifaceted Phenomenon"
   - Status: not started
   - Summary: 
   - Digest: The recently discovered $d^*(2380)$ hexaquark is expected to be the lightest member of an extended SU(3) antidecuplet of hexaquark states. The experimental search for the other heavier and strange partners of the $d^*(2380)$ in the antidecuplet is a challenging task. Evaluating the most appropriate 
   - ArXiv: http://arxiv.org/abs/2012.11449v1

2. RAG4GFM: Graph Retrieval Augmented Generation
   - Status: not started
   - Summary: 

3. MoBA: Mixture of Block Attention for Long-Context LLMs
   - Status: not started
   - Summary: 
   - Digest: Scaling the effective context length is essential for advancing large language models (LLMs) toward artificial general intelligence (AGI). However, the quadratic increase in computational complexity inherent in traditional attention mechanisms presents a prohibitive overhead. Existing approaches eit
   - ArXiv: http://arxiv.org/abs/2502.13189v1



Today's top 3 picks:

1. Non-Parametric Choice Model That Learns How Users Choose Between Recommended Options
   - Status: not started
   - Summary: 
   - Digest: Choice models predict which items users choose from presented options. In recommendation settings, they can infer user preferences while countering exposure bias. In contrast with traditional univariate recommendation models, choice models consider which competitors appeared with the chosen item. Th
   - ArXiv: http://arxiv.org/abs/2507.20035v1

2. DeLLMphi: A Multi-Turn Method for Multi-Agent Forecasting
   - Status: not started
   - Summary: 

3. VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. MindForge: Empowering Embodied Agents with Theory of Mind for Lifelong Cultural Learning
   - Status: not started
   - Summary: 
   - Digest: Embodied agents powered by large language models (LLMs), such as Voyager, promise open-ended competence in worlds such as Minecraft. However, when powered by open-weight LLMs they still falter on elementary tasks after domain-specific fine-tuning. We propose MindForge, a generative-agent framework f
   - ArXiv: http://arxiv.org/abs/2411.12977v5

2. FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management
   - Status: not started
   - Summary: 
   - Digest: Large Language Models (LLMs) are increasingly deployed in multi-turn conversational applications, where the management of the Key-Value (KV) Cache presents a significant bottleneck. The linear growth of the KV Cache with dialogue history imposes substantial computational costs, and existing eviction
   - ArXiv: http://arxiv.org/abs/2505.15347v2

3. LLMs as Reliable Evaluators for Serendipity Evaluation in RecSys
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. VASA-3D: Lifelike Audio-Driven Gaussian Head Avatars from a Single Image
   - Status: not started
   - Summary: 

2. PREAMBLE: Private and Efficient Aggregation via Block Sparse Vectors
   - Status: not started
   - Summary: 
   - Digest: We revisit the problem of secure aggregation of high-dimensional vectors in a two-server system such as Prio. These systems are typically used to aggregate vectors such as gradients in private federated learning, where the aggregate itself is protected via noise addition to ensure differential priva
   - ArXiv: http://arxiv.org/abs/2503.11897v2

3. Full-page layouts with multiple carousels in video streaming platforms
   - Status: not started
   - Summary: 



Today's top 3 picks:

1. Self-Guided Hierarchical Exploration for Generalist Foundation Model Web Agents
   - Status: not started
   - Summary: 

2. Provably Efficient Multi-Task Meta Bandit Learning via Shared Representations
   - Status: not started
   - Summary: 

3. Non-Parametric Choice Model That Learns How Users Choose Between Recommended Options
   - Status: not started
   - Summary: 
   - Digest: Choice models predict which items users choose from presented options. In recommendation settings, they can infer user preferences while countering exposure bias. In contrast with traditional univariate recommendation models, choice models consider which competitors appeared with the chosen item. Th
   - ArXiv: http://arxiv.org/abs/2507.20035v1



Today's top 3 picks:

1. Addressing Multi-stakeholder Fairness Concerns in Recommender Systems
   - Status: not started
   - Summary: 
   - Digest: This position paper summarizes our published review on individual and multistakeholder fairness in Tourism Recommender Systems (TRS). Recently, there has been growing attention to fairness considerations in recommender systems (RS). It has been acknowledged in research that fairness in RS is often c
   - ArXiv: http://arxiv.org/abs/2309.02052v1

2. Stable Gradients for Stable Learning at Scale in Deep Reinforcement Learning
   - Status: not started
   - Summary: 
   - Digest: Scaling deep reinforcement learning networks is challenging and often results in degraded performance, yet the root causes of this failure mode remain poorly understood. Several recent works have proposed mechanisms to address this, but they are often complex and fail to highlight the causes underly
   - ArXiv: http://arxiv.org/abs/2506.15544v1

3. MAT-Agent: Adaptive Multi-Agent Training Optimization
   - Status: not started
   - Summary: 
   - Digest: Multi-label image classification demands adaptive training strategies to navigate complex, evolving visual-semantic landscapes, yet conventional methods rely on static configurations that falter in dynamic settings. We propose MAT-Agent, a novel multi-agent framework that reimagines training as a co
   - ArXiv: http://arxiv.org/abs/2510.17845v1



Today's top 3 picks:

1. GAM-Agent: Game-Theoretic and Uncertainty-Aware Collaboration
   - Status: not started
   - Summary: 
   - Digest: We propose GAM-Agent, a game-theoretic multi-agent framework for enhancing vision-language reasoning. Unlike prior single-agent or monolithic models, GAM-Agent formulates the reasoning process as a non-zero-sum game between base agents--each specializing in visual perception subtasks--and a critical
   - ArXiv: http://arxiv.org/abs/2505.23399v1

2. AgentRecBench: Benchmarking LLM Agent-based Personalized RecSys
   - Status: not started
   - Summary: 

3. Benefiting from Negative yet Informative Feedback by Contrasting Opposing Sequential Patterns
   - Status: not started
   - Summary: 
   - Digest: We consider the task of learning from both positive and negative feedback in a sequential recommendation scenario, as both types of feedback are often present in user interactions. Meanwhile, conventional sequential learning models usually focus on considering and predicting positive interactions, i
   - ArXiv: http://arxiv.org/abs/2508.14786v1



Today's top 3 picks:

1. Self-Guided Hierarchical Exploration for Generalist Foundation Model Web Agents
   - Status: not started
   - Summary: 

2. Info-Theoretic Reward Decomposition for Generalizable RLHF
   - Status: not started
   - Summary: 

3. NeSyPr: Neurosymbolic Proceduralization For Efficient Embodied Reasoning
   - Status: not started
   - Summary: 
   - Digest: We address the challenge of adopting language models (LMs) for embodied tasks in dynamic environments, where online access to large-scale inference engines or symbolic planners is constrained due to latency, connectivity, and resource limitations. To this end, we present NeSyPr, a novel embodied rea
   - ArXiv: http://arxiv.org/abs/2510.19429v1



Today's top 3 picks:

1. FlowKV: Enhancing Multi-Turn Conversational Coherence in LLMs via Isolated Key-Value Cache Management
   - Status: not started
   - Summary: 
   - Digest: Large Language Models (LLMs) are increasingly deployed in multi-turn conversational applications, where the management of the Key-Value (KV) Cache presents a significant bottleneck. The linear growth of the KV Cache with dialogue history imposes substantial computational costs, and existing eviction
   - ArXiv: http://arxiv.org/abs/2505.15347v2

2. MoBA: Mixture of Block Attention for Long-Context LLMs
   - Status: not started
   - Summary: 
   - Digest: Scaling the effective context length is essential for advancing large language models (LLMs) toward artificial general intelligence (AGI). However, the quadratic increase in computational complexity inherent in traditional attention mechanisms presents a prohibitive overhead. Existing approaches eit
   - ArXiv: http://arxiv.org/abs/2502.13189v1

3. RAG4GFM: Graph Retrieval Augmented Generation
   - Status: not started
   - Summary: 

