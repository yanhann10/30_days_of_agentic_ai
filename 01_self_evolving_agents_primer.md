# Day 01 Reading Notes: Self-Evolving Agents

I am interested in agentic systems that can autonomously design or improve other agents, with an emphasis on self-evolving mechanisms. Below are my notes from several recent papers I explored today.

---

## Automated Design of Agentic Systems via Meta-Agent Programming (ADAS)

**Paper:** https://arxiv.org/pdf/2408.08435
**Code:** https://github.com/ShengranHu/ADAS

### Overview

ADAS introduces a meta agent that automatically designs and refines new agent architectures. The system treats previously successful agents as stepping stones and evolves new ones that outperform strong hand-designed baselines across a variety of tasks.

### Method

- The meta agent is conditioned on an expanding archive of past agents and their performance.
- The meta agent writes each candidate agent's forward function.
- For every iteration, it proposes a new agent concept, writes the code, and performs two rounds of self-reflection to check novelty and correctness, with up to five refinement loops.
- Successful agents are stored in the archive with scores, confidence intervals, and textual insights on what should be the next interesting agent.
- The system queries Semantic Scholar to assess novelty and saturation of ideas.

### Findings

- On benchmarks including reading comprehension, multi-task problem solving, and math or science question answering, ADAS consistently surpasses strong hand-crafted baselines.
- There is cross-domain and cross-model transferability.

## Can LLMs Generate Novel Research Ideas?

**Paper:** https://arxiv.org/abs/2409.04109
**Code:** https://github.com/NoviScl/AI-Researcher

### Overview

A Stanford study investigates whether LLMs can generate novel and high-quality NLP research ideas.

### Method

- The system uses retrieval augmented generation through APIs such as Semantic Scholar to expose the LLM to relevant literature.
- For a chosen topic, it retrieves, filters, and ranks papers, then conditions the LLM on selected works to produce research ideas. It generates a large pool of candidates and deduplicates.
- An LLM-based ranker is chosen through zero-shot evaluation on paired ICLR accept or reject examples.
- Human experts then judge novelty, feasibility, and overall quality in a blinded assessment.

### Observations

- Ideas tend to cluster around a limited set of themes and show less variety.
- Some ideas misuse datasets, skip strong baselines, or assume unrealistic setups, indicating gaps in awareness of empirical best practices.
- Human ideas are typically more feasible and grounded in real experimentation strategies, revealing an ideation-execution gap in ideas generated by LLMs using the specified methods.

## AI-Scientist-v2: Workshop-Level Automated Scientific Discovery via Agentic Tree Search

**Paper:** https://arxiv.org/abs/2504.08066
**Code:** https://github.com/SakanaAI/AI-Scientist-v2

### Overview

AI-Scientist-v2 conducts end-to-end automated research. It proposes hypotheses, designs experiments, runs training, analyzes results, and writes scientific papers.

### Method

- Each node in the search tree represents a partial experiment state, including hypothesis, code, configs, and results.
- Agents attached to the node propose actions such as model changes, hyperparameter updates, data modifications, and ablations.
- The system uses best-first tree search (BFTS) to prioritize the most promising node for expansion.
- A writing agent then drafts a complete workshop-style paper with text and figures.

### Results

- One of the manuscripts created entirely by AI-Scientist-v2 submitted to an ICLR 2025 workshop was accepted.

## AI Research Agents for Machine Learning: Search, Exploration, and Generalization in MLE-bench

**Paper:** https://arxiv.org/abs/2507.02554
**Code:** https://github.com/facebookresearch/aira-dojo

### Method

- Agents explore a directed graph where each node is an artifact such as an idea, experiment, or partial solution.
- Operators include draft, debug, improve, memory retrieval, and crossover.
- Search strategies include greedy expansion, Monte Carlo tree search, and evolutionary approaches.
- Termination is based on wall-clock time or a maximum number of artifacts.
- The system is assessed on MLGym, Re-BENCH, MLAgentBench, and AIRA-Dojo, which focus on long-running research tasks.

It introduced the concept of Prompt-adaptive complexity to avoid over-engineering. It assesses the complexity of a node based on the children they have, and the level of complexity guides the action (e.g. <2 children -> simple baseline update, <4 -> moderate refinement)

### Findings

- The interplay between the search strategy and the operator set is critical for achieving high performance.
- Operators can be the bottleneck more so than the search strategy.

## Kosmos: An AI Scientist for Autonomous Discovery

**Paper:** https://arxiv.org/abs/2511.02824
**Code:** Not available

### Overview

Kosmos, developed by an SF startup, expands beyond tackling ML and math problems and veers into broader scientific disciplines. It aims to perform data analysis, literature review, and scientific hypothesis generation.

### Method

- A structured world model acts as a shared memory between all agents (not many details provided in the paper).
- Up to two hundred specialized agents run asynchronously, synthesizing 1500 scientific papers per run.
- Each cycle updates the world model, which then produces new tasks for the next cycle.

### Findings

- About 80% accuracy is reported on data analysis and literature retrieval.
- Less than 60% accuracy is achieved on tasks that require scientific interpretation.

### Limitations

- Lacking 'scientific' taste
- Stochasticity in discoveries
- Sensitive to initial prompts

## AgentNet: Decentralized Evolutionary Coordination for LLM-based Multi-Agent Systems

**Paper:** https://arxiv.org/abs/2504.00587
**Code:** https://github.com/zoe-yyx/AgentNet

### Method

- AgentNet replaces a central orchestrator with fully decentralized coordination.
- Agents communicate along a dynamic directed acyclic graph.
- Each agent includes a router for delegation and an executor for task completion.

### Findings

- Shows emergent specialization without predefined roles.
- Shows competitive or better results compared to centralized multi-agent systems on Big-Bench-Hard benchmark.

## AgentBreeder: Mitigating the AI Safety Risks of Multi-Agent Scaffolds

**Paper:** https://arxiv.org/abs/2502.00757
**Code:** https://github.com/J-Rosser-UK/AgentBreeder

### Method

AGENTBREEDER is an evolutionary, open-ended framework designed for the multi-objective self-improvement of multi-agent scaffolds. It evaluates the dual objectives of capability and safety.

**Steps:**

1. **Evaluate scaffolds:** The newly generated scaffolds are evaluated for capability and safety using predefined benchmarks.
2. **Compute embeddings and cluster:** Each scaffold's descriptor embedding is computed, and the population is clustered.
3. **Identify Pareto elites:** Within each cluster, the Pareto front is found using capability and safety scores, forming the elite set.
4. **Generate offspring:** A meta agent performs crossover or mutation on weighted samples of one or two elites to create new scaffold candidates.
5. **Update population:** The new offspring scaffolds are merged with the existing population to form the next generation.
6. **Iterate and explore:** The generation count increases, and the entire process repeats.

**Multi-objective optimization through three modes:**

- **Blue mode:** Evolves robust and capable scaffolds.
- **Red mode:** Finds scaffolds vulnerable to adversarial attacks.
- **Capable mode:** Focuses strictly on capability.

### Findings

- Joint optimization of capability and safety outperforms capability-only approaches.
- BlueAgentBreeder produces strong reasoning and math performance with improved safety scores.
- RedAgentBreeder uncovers vulnerable scaffolds quickly, showing automated adversarial discovery.
- Gains in capability can hide safety weaknesses, illustrating the need for multi-objective evaluation.
